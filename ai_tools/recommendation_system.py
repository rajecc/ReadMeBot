import time
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from googletrans import Translator
from sentence_transformers import SentenceTransformer, util
from typing import List, Dict
from database.database import load_recommendation_history, save_recommendation_history

# –ò–º–ø–æ—Ä—Ç —Ñ—É–Ω–∫—Ü–∏–π –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ analyze_system –∏ —Å–∂–∞—Ç–∏—è –∏–∑ summarize_system
from ai_tools.analyze_system import extract_tags_and_genres
from ai_tools.summarize_system import compress_text

similarity_model = SentenceTransformer("all-MiniLM-L6-v2")

def format_books(book_list):
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–Ω–∏–≥ –≤ —á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥.
    
    :param book_list: —Å–ø–∏—Å–æ–∫ –∫–Ω–∏–≥, –≥–¥–µ –∫–∞–∂–¥–∞—è –∫–Ω–∏–≥–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ —Å–ª–æ–≤–∞—Ä–µ–º —Å –∫–ª—é—á–∞–º–∏ 'title' –∏ 'authors'
    :return: —Å—Ç—Ä–æ–∫–∞ —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Å–ø–∏—Å–∫–æ–º –∫–Ω–∏–≥
    """
    formatted_books = []
    for book in book_list:
        title = book.get("Title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è")
        authors = book.get("Authors", "–ë–µ–∑ –∞–≤—Ç–æ—Ä–∞").replace("By ", "").strip()
        formatted_books.append(f"üìñ {title}\n   –ê–≤—Ç–æ—Ä: {authors}\n")
    
    return "\n".join(formatted_books)

# ------------------------------
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞ —Å —Ä—É—Å—Å–∫–æ–≥–æ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π
def translate_to_english(text: str) -> str:
    translator = Translator()
    return translator.translate(text, dest='en').text

# ------------------------------
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–µ–∫—Å—Ç–∞–º–∏
def compute_similarity(text1: str, text2: str) -> float:
    """
    –í—ã—á–∏—Å–ª–∏—Ç—å –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–µ–∫—Å—Ç–∞–º–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.
    """
    embeddings1 = similarity_model.encode([text1], convert_to_tensor=True)
    embeddings2 = similarity_model.encode([text2], convert_to_tensor=True)
    cosine_similarity = util.pytorch_cos_sim(embeddings1, embeddings2)
    return cosine_similarity.item()


# ------------------------------
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞
def get_preferences_from_input(user_input: str) -> Dict[str, List[str]]:
    """
    –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–≥–∏ –∏ –∂–∞–Ω—Ä—ã –∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞.
    –ü–µ—Ä–µ–≤–æ–¥ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ–º, –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è, –∑–∞—Ç–µ–º –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç.
    """
    # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤–≤–æ–¥ (–µ—Å–ª–∏ –±–∞–∑–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å —Ç–µ–≥–∏ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º)
    translated_input = translate_to_english(user_input)
    extracted_data = extract_tags_and_genres(translated_input)
    print(extracted_data)
    return extracted_data


# ------------------------------
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –∏–∑ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–Ω–∏–≥–∏
def get_preferences_from_history(selected_history: str) -> Dict[str, List[str]]:
    """
    –°–∂–∞—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–Ω–∏–≥–∏ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –∏ –∏–∑–≤–ª–µ—á—å —Ç–µ–≥–∏ –∏ –∂–∞–Ω—Ä—ã.
    """
    # –°–∂–∏–º–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∫–Ω–∏–≥–∏
    compressed_text = compress_text(selected_history)
    all_tags, all_genres = [], []

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–≥–∏ –∏ –∂–∞–Ω—Ä—ã –∏–∑ —Å–∂–∞—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    extracted_data = extract_tags_and_genres(compressed_text)
    print(extracted_data)
    all_tags.extend(extracted_data.get('tags', []))
    all_genres.extend(extracted_data.get('genres', []))

    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    return {"tags": list(set(all_tags)), "genres": list(set(all_genres))}, compressed_text

# ------------------------------
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π (–µ—Å–ª–∏ —É—á—Ç–µ–Ω—ã –∏ –≤–≤–æ–¥, –∏ –∏—Å—Ç–æ—Ä–∏—è)
def combine_preferences(pref_input: Dict[str, List[str]], pref_history: Dict[str, List[str]]) -> Dict[str, List[str]]:
    """
    –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ç–µ–≥–∏ –∏ –∂–∞–Ω—Ä—ã, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞ –∏ –∏—Å—Ç–æ—Ä–∏–∏.
    """
    combined_tags = list(set(pref_input.get("tags", []) + pref_history.get("tags", [])))
    combined_genres = list(set(pref_input.get("genres", []) + pref_history.get("genres", [])))
    return {"tags": combined_tags, "genres": combined_genres}

def compute_similarity(text1: str, text2: str) -> float:
    """
    –í—ã—á–∏—Å–ª–∏—Ç—å –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–µ–∫—Å—Ç–∞–º–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.
    """
    embeddings1 = similarity_model.encode([text1], convert_to_tensor=True)
    embeddings2 = similarity_model.encode([text2], convert_to_tensor=True)
    cosine_similarity = util.pytorch_cos_sim(embeddings1, embeddings2)
    return cosine_similarity.item()

def combine_preferences(pref_input, pref_history):
    """
    –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ç–µ–≥–∏ –∏ –∂–∞–Ω—Ä—ã, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞ –∏ –∏—Å—Ç–æ—Ä–∏–∏.
    """
    combined_tags = list(set(pref_input.get("tags", []) + pref_history.get("tags", [])))
    combined_genres = list(set(pref_input.get("genres", []) + pref_history.get("genres", [])))
    return {"tags": combined_tags, "genres": combined_genres}

def filter_books_by_tags(dataset, preferences, max_candidates=40):
    """–§–∏–ª—å—Ç—Ä—É–µ—Ç –∫–Ω–∏–≥–∏ –ø–æ —Ç–µ–≥–∞–º –∏ –æ—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–µ –±–æ–ª–µ–µ max_candidates –∫–Ω–∏–≥."""
    filtered_books = dataset[dataset["category"].apply(lambda x: any(pref in x for pref in preferences))].copy()
    return filtered_books.sample(min(len(filtered_books), max_candidates))  # –û—Å—Ç–∞–≤–ª—è–µ–º –Ω–µ –±–æ–ª–µ–µ 20 –∫–Ω–∏–≥

def search_books_1_mode(selected_history, dataset):
    start_time = time.time()
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å–∂–∞—Ç—ã–π —Ç–µ–∫—Å—Ç –∫–Ω–∏–≥–∏ —Å 20 –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–Ω–∏–≥–∞–º–∏ –ø–æ —Ç–µ–≥–∞–º –∏ –≤—ã–±–∏—Ä–∞–µ—Ç —Ç–æ–ø-5."""
    pref_history, compressed_text = get_preferences_from_history(selected_history)
    preferences = pref_history["tags"] + pref_history["genres"]
    
    filtered_books = filter_books_by_tags(dataset, preferences)

    filtered_books["similarity"] = filtered_books["Description"].apply(lambda x: compute_similarity(compressed_text, x))

    top_books = filtered_books.sort_values(by="similarity", ascending=False).head(5)
    recommendations = top_books[["Title", "Authors"]].to_dict(orient="records")
    for _, book in top_books.iterrows():
        print(f"{book['Title']} - {book['Authors']}, Similarity: {book['similarity']}")
    # recommendations_str = "; ".join(f"{book['Title']} - {book['Authors']}" for book in recommendations)
    print(f"Execution time: {time.time() - start_time:.4f} seconds")
    return recommendations

def search_books_2_mode(user_input, dataset):
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–≤–æ–¥ —Å 20 –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–Ω–∏–≥–∞–º–∏ –ø–æ —Ç–µ–≥–∞–º –∏ –≤—ã–±–∏—Ä–∞–µ—Ç —Ç–æ–ø-5."""
    pref_input = get_preferences_from_input(user_input)
    preferences = pref_input["tags"] + pref_input["genres"]

    filtered_books = filter_books_by_tags(dataset, preferences)

    filtered_books["similarity"] = filtered_books["Description"].apply(lambda x: compute_similarity(user_input, x))
        
    top_books = filtered_books.sort_values(by="similarity", ascending=False).head(5)
    recommendations = top_books[["Title", "Authors"]].to_dict(orient="records")
    for _, book in top_books.iterrows():
        print(f"{book['Title']} - {book['Authors']}, Similarity: {book['similarity']}")

    return recommendations

def search_books_3_mode(user_input, selected_history, dataset):
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –∏–∑ –≤–≤–æ–¥–∞ –∏ –∏—Å—Ç–æ—Ä–∏–∏, —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç 20 –∫–Ω–∏–≥ –ø–æ —Ç–µ–≥–∞–º –∏ –≤—ã–±–∏—Ä–∞–µ—Ç —Ç–æ–ø-5."""
    pref_input = get_preferences_from_input(user_input)
    pref_history = get_preferences_from_history(selected_history)
    pref_combine = combine_preferences(pref_input, pref_history)
    preferences = pref_combine["tags"] + pref_combine["genres"]

    filtered_books = filter_books_by_tags(dataset, preferences)

    filtered_books["similarity"] = filtered_books["Description"].apply(lambda x: compute_similarity(user_input, x))

    top_books = filtered_books.sort_values(by="similarity", ascending=False).head(5)
    recommendations = top_books[["Title", "Authors"]].to_dict(orient="records")
    for _, book in top_books.iterrows():
        print(f"{book['Title']} - {book['Authors']}, Similarity: {book['similarity']}")
    return recommendations


# def search_books_1_mode(selected_history, dataset):
#     pref_history = get_preferences_from_history(selected_history)
#     preferences = pref_history["tags"] + pref_history["genres"]
    
#     # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–Ω–∏–≥–∏, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º–∏
#     filtered_books = dataset[dataset["category"].apply(lambda x: any(pref in x for pref in preferences))].copy()
#     print(filtered_books)
    
#     # –ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
#     filtered_books["match_count"] = filtered_books["category"].apply(lambda x: sum(pref in x for pref in preferences))
    
#     # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤ —É–±—ã–≤–∞—é—â–µ–º –ø–æ—Ä—è–¥–∫–µ
#     top_books = filtered_books.sort_values(by="match_count", ascending=False).head(5)
    
#     # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∫–Ω–∏–≥–∞–º–∏
#     recommendations = top_books[["Title", "Authors"]].to_dict(orient="records")
#     print(recommendations)

#     # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–Ω–∏–≥–∏ –≤ —Å—Ç—Ä–æ–∫—É "–ù–∞–∑–≤–∞–Ω–∏–µ - –ê–≤—Ç–æ—Ä" —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º "; "
#     recommendations_str = "; ".join(f"{book['Title']} - {book['Authors']}" for book in recommendations)
#     print(recommendations_str)

#     return recommendations,recommendations_str
# def search_books_2_mode(user_input, dataset):
#     pref_input = get_preferences_from_input(user_input)
    
#     # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–≥–∏ –∏ –∂–∞–Ω—Ä—ã –≤ –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫
#     preferences = pref_input["tags"] + pref_input["genres"]
    
#     # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–Ω–∏–≥–∏, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º–∏
#     filtered_books = dataset[dataset["category"].apply(lambda x: any(pref in x for pref in preferences))].copy()
#     print(filtered_books)
    
#     # –ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
#     filtered_books["match_count"] = filtered_books["category"].apply(lambda x: sum(pref in x for pref in preferences))
    
#     # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤ —É–±—ã–≤–∞—é—â–µ–º –ø–æ—Ä—è–¥–∫–µ
#     top_books = filtered_books.sort_values(by="match_count", ascending=False).head(5)
    
#     # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∫–Ω–∏–≥–∞–º–∏
#     recommendations = top_books[["Title", "Authors"]].to_dict(orient="records")

#     # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–Ω–∏–≥–∏ –≤ —Å—Ç—Ä–æ–∫—É "–ù–∞–∑–≤–∞–Ω–∏–µ - –ê–≤—Ç–æ—Ä" —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º "; "
#     recommendations_str = "; ".join(f"{book['Title']} - {book['Authors']}" for book in recommendations)

#     return recommendations, recommendations_str


# def search_books_3_mode(user_input, selected_history, dataset):
#     """
#     –ü–æ–∏—Å–∫ –∫–Ω–∏–≥ –≤ –±–∞–∑–µ —Å —É—á–µ—Ç–æ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ –∫–Ω–∏–≥ –∏ —Ç–µ–∫—Å—Ç–∞–º–∏ –≤–≤–æ–¥–∞/–∏—Å—Ç–æ—Ä–∏–∏.
#     """
#     # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –∏–∑ –≤–≤–æ–¥–∞ –∏ –∏—Å—Ç–æ—Ä–∏–∏
#     pref_input = get_preferences_from_input(user_input)
#     pref_history = get_preferences_from_history(selected_history)

#     # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
#     pref_combine = combine_preferences(pref_input, pref_history)
#     preferences = pref_combine["tags"] + pref_combine["genres"]
#     # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–Ω–∏–≥–∏, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º–∏
#     filtered_books = dataset[dataset["category"].apply(lambda x: any(pref in x for pref in preferences))].copy()
#     print(filtered_books)
    
#     # –ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
#     filtered_books["match_count"] = filtered_books["category"].apply(lambda x: sum(pref in x for pref in preferences))
    
#     # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤ —É–±—ã–≤–∞—é—â–µ–º –ø–æ—Ä—è–¥–∫–µ
#     top_books = filtered_books.sort_values(by="match_count", ascending=False).head(5)
    
#     # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∫–Ω–∏–≥–∞–º–∏
#     recommendations = top_books[["Title", "Authors"]].to_dict(orient="records")

#     # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–Ω–∏–≥–∏ –≤ —Å—Ç—Ä–æ–∫—É "–ù–∞–∑–≤–∞–Ω–∏–µ - –ê–≤—Ç–æ—Ä" —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º "; "
#     recommendations_str = "; ".join(f"{book['Title']} - {book['Authors']}" for book in recommendations)

#     return recommendations, recommendations_str

# ------------------------------
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
def get_book_recommendations(user_input, selected_book, mode, user_id, history_exclude_option, dataset):
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ç—Ä—ë–º —Ä–µ–∂–∏–º–∞–º:
      1. –£—á–∏—Ç—ã–≤–∞—Ç—å –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–≤–æ–¥, –∏ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∫–Ω–∏–≥–∏ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏.
      2. –£—á–∏—Ç—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–≤–æ–¥.
      3. –£—á–∏—Ç—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∫–Ω–∏–≥–∏ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏.
    –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –∏—Å–∫–ª—é—á–∞–µ—Ç —Ä–∞–Ω–µ–µ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –∫–Ω–∏–≥–∏.
    """

    recommendations = []
    if history_exclude_option:
        previously_recommended = load_recommendation_history(user_id)
        dataset = dataset[~dataset['Title'].isin(previously_recommended)]

    if mode == 1:
        # –†–µ–∂–∏–º 1: –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞ –∏ –∏—Å—Ç–æ—Ä–∏–∏
        recommendations = search_books_1_mode(selected_book, dataset)

    elif mode == 2:
        # –†–µ–∂–∏–º 2: —É—á–∏—Ç—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–≤–æ–¥
        recommendations = search_books_2_mode(user_input, dataset)

    elif mode == 3:
        # –†–µ–∂–∏–º 3: —É—á–∏—Ç—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –∫–Ω–∏–≥–∏ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏
        recommendations= search_books_3_mode(user_input, selected_book, dataset)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã—Ö –∫–Ω–∏–≥
    save_recommendation_history(user_id, [book['Title'] for book in recommendations])
   
    return format_books(recommendations)

